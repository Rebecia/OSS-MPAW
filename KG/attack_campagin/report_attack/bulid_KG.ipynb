{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    " \n",
    "file_path = ''\n",
    "df = pd.read_excel(file_path)\n",
    " \n",
    "G = nx.Graph()\n",
    "\n",
    "for source in df['source'].dropna().unique():\n",
    "     \n",
    "    sub_df = df[df['source'] == source]\n",
    "    \n",
    "     \n",
    "    names = sub_df['name'].tolist()\n",
    "    ids = sub_df['ID'].tolist()\n",
    "    \n",
    "     \n",
    "    for _, row in sub_df.iterrows():\n",
    "         \n",
    "        if isinstance(row['published_at'], datetime):\n",
    "            time_str = row['published_at'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            time_str = row['published_at']\n",
    "        \n",
    "        G.add_node(row['ID'], \n",
    "                   name=row['name'],\n",
    "                   report=row['source'],\n",
    "                   Source=row['Source'],\n",
    "                   status=row['status'], \n",
    "                   time=time_str)\n",
    "    \n",
    "     \n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i + 1, len(ids)):\n",
    "            G.add_edge(ids[i], ids[j], source=source)\n",
    "\n",
    " \n",
    "output_path = './ruby_graph.json'   \n",
    "data = nx.node_link_data(G)   \n",
    "\n",
    " \n",
    "def custom_json_serializer(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    raise TypeError(f'Object of type {obj.__class__.__name__} is not JSON serializable')\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(data, f, indent=4, default=custom_json_serializer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    " \n",
    "subgraphs = list(nx.connected_components(G))\n",
    "\n",
    " \n",
    "subgraphs_dir = ''\n",
    "os.makedirs(subgraphs_dir, exist_ok=True)\n",
    "\n",
    " \n",
    "for idx, component in enumerate(subgraphs):\n",
    "    subgraph = G.subgraph(component)\n",
    "    subgraph_data = nx.node_link_data(subgraph)\n",
    "    \n",
    "    subgraph_path = os.path.join(subgraphs_dir, f'subgraph_{idx + 1}.json')\n",
    "    print(f'subgraph_{idx + 1}.json'+': '+ str(len(component)))\n",
    "    with open(subgraph_path, 'w') as f:\n",
    "        json.dump(subgraph_data, f, indent=4, default=custom_json_serializer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebCrawler_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "import os\n",
    "\n",
    " \n",
    "df1 = pd.read_excel('')\n",
    "df2 = pd.read_excel('')\n",
    "\n",
    " \n",
    "output_dir = ''\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    " \n",
    "graph_counter = 0\n",
    "\n",
    " \n",
    "for idx, row in df1.iterrows():\n",
    "    found_names = eval(row['found_names'])   \n",
    "    report_url = row['url']\n",
    "\n",
    "     \n",
    "    G = nx.Graph()\n",
    "\n",
    "     \n",
    "    node_ids = []\n",
    "    for name in found_names:\n",
    "         \n",
    "        match_row = df2[df2['name'] == name]\n",
    "        \n",
    "        if not match_row.empty:\n",
    "             \n",
    "            for _, match in match_row.iterrows():\n",
    "                node_id = match['id']   \n",
    "                node_attrs = match.to_dict()\n",
    "                node_attrs['url'] = report_url   \n",
    "                G.add_node(node_id, **node_attrs)\n",
    "                node_ids.append(node_id)\n",
    "\n",
    "     \n",
    "    for i in range(len(node_ids)):\n",
    "        for j in range(i + 1, len(node_ids)):\n",
    "            G.add_edge(node_ids[i], node_ids[j], report=report_url)\n",
    "\n",
    "     \n",
    "    print(f\"Graph {graph_counter}:\")\n",
    "    print(f\"URL: {report_url}\")\n",
    "    print(\"Nodes:\")\n",
    "    for node_id in G.nodes(data=True):\n",
    "        print(node_id)\n",
    "    print(\"\\n\")\n",
    "\n",
    "     \n",
    "    output_path = os.path.join(output_dir, f'graph_{graph_counter}.json')\n",
    "    output_data = nx.node_link_data(G)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "\n",
    "     \n",
    "    graph_counter += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
