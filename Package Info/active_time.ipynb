{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.ticker as ticker\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for similar graph\n",
    "\n",
    "def process_multiple_excels(input_excel_paths, output_excel_path):\n",
    "    all_results = []\n",
    "\n",
    "    for input_path in input_excel_paths:\n",
    "        print(f\"⏳ Processing: {input_path}\")\n",
    "        df = pd.read_excel(input_path)\n",
    "\n",
    "        # Filter out rows where 'published_at' is 'Not available'\n",
    "        df = df[df['published_at'] != 'Not available']\n",
    "\n",
    "        # Ensure the 'published_at' column is in datetime format\n",
    "        df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')\n",
    "\n",
    "        # Iterate through each cluster group\n",
    "        for cluster, group in df.groupby('cluster'):\n",
    "            group_sorted = group.sort_values(by='published_at')\n",
    "            \n",
    "            if len(group_sorted) > 1:\n",
    "                time_diff = group_sorted['published_at'].max() - group_sorted['published_at'].min()\n",
    "                time_diff_in_days = time_diff.total_seconds() / 86400\n",
    "                time_diff_str = f\"{time_diff_in_days:.2f}\"\n",
    "            else:\n",
    "                time_diff_str = \"0.00\"\n",
    "\n",
    "            source_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "            cluster_id = f\"{source_name}_{cluster}\"\n",
    "            all_results.append([cluster_id, time_diff_str])\n",
    "\n",
    "    result_df = pd.DataFrame(all_results, columns=['cluster', 'time'])\n",
    "    result_df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"✅ All results saved to: {output_excel_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_excel_paths = [\n",
    "        '../KG/Similar_Edge/ruby_end.xlsx',\n",
    "        '../KG/Similar_Edge/npm_end.xlsx',\n",
    "        '../KG/Similar_Edge/pypi_end.xlsx'\n",
    "    ]\n",
    "    output_excel_path = './active_time.xlsx'\n",
    "    process_multiple_excels(input_excel_paths, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dependent-hidden/co-existing graph\n",
    "\n",
    "time_name = 'published_at'\n",
    "# time_name = 'time'\n",
    "def extract_time_difference_from_subgraph(subgraph):\n",
    "    nodes = subgraph['nodes']\n",
    "\n",
    "    for node in nodes:\n",
    "        if node[time_name] != \"Not available\":\n",
    "            node[time_name] = datetime.fromisoformat(node[time_name][:-1])\n",
    "        else:\n",
    "            node[time_name] = None\n",
    "\n",
    "    dates = [node[time_name] for node in nodes if node[time_name] is not None]\n",
    "    if dates:\n",
    "        min_date = min(dates)\n",
    "        max_date = max(dates)\n",
    "        time_diff = max_date - min_date  \n",
    "\n",
    "        time_diff_in_days = time_diff.total_seconds() / 86400  # 86400s = 1d\n",
    "        time_diff_str = f\"{time_diff_in_days:.2f}\"\n",
    "    else:\n",
    "        time_diff_str = 'None'\n",
    "    \n",
    "    return time_diff_str\n",
    "\n",
    "def process_json_files_in_folders(folders):\n",
    "    time_differences = []\n",
    "\n",
    "    for folder_path in folders:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for filename in files:\n",
    "                if filename.endswith('.json'):\n",
    "                    file_path = os.path.join(root, filename)\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        subgraph = json.load(file)\n",
    "                        time_diff_str = extract_time_difference_from_subgraph(subgraph)\n",
    "                        \n",
    "                        time_differences.append({\n",
    "                            'file_path': file_path,\n",
    "                            'time': time_diff_str\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(time_differences)\n",
    "    output_path = './active_time.xlsx'\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"Time differences saved to {output_path}\")\n",
    "\n",
    "# TODO\n",
    "folders = [\n",
    "# # dependent-hidden graph\n",
    "#   '../KG/Dependency_Edge/metadata_dep/npm',\n",
    "#   '../KG/Dependency_Edge/sourcecode_dep/npm',\n",
    "#   '../KG/Dependency_Edge/metadata_dep/pypi',\n",
    "#   '../KG/Dependency_Edge/sourcecode_dep/pypi',\n",
    "#   '../KG/Dependency_Edge/metadata_dep/ruby',\n",
    "#   '../KG/Dependency_Edge/sourcecode_dep/ruby'\n",
    "\n",
    "# # co-existing graph\n",
    "  '../KG/Co-existing_Edge/source_report/npm',\n",
    "  '../KG/Co-existing_Edge/WebCrawler_report/npm',\n",
    "  '../Co-existing_Edge/source_report/pypi',\n",
    "  '../KG/Co-existing_Edge/WebCrawler_report/pypi',\n",
    "  '../KG/Co-existing_Edge/source_report/ruby',\n",
    "  '../KG/Co-existing_Edge/WebCrawler_report/ruby'\n",
    "]\n",
    "process_json_files_in_folders(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paint\n",
    "\n",
    "label_fontsize = 27\n",
    "tick_fontsize = 22\n",
    "barlabel_fontsize = 24\n",
    "legend_fontsize = 24\n",
    "\n",
    "linewidth = 3\n",
    "markersize = 12\n",
    "indicator_linewidth = 2\n",
    "indicator_color = 'grey'\n",
    "indicator_linestyle = 'dotted'\n",
    "\n",
    "dpi = 600\n",
    "figsize = (9, 6)\n",
    "mpl.use('TkAgg')\n",
    "plt.rc('font', family='Times New Roman')\n",
    "\n",
    "def xlsx_to_csv_pd(path_xls):\n",
    "    temp = path_xls.rsplit('.', 1)\n",
    "    path_csv = temp[0] + '.csv'\n",
    "    data_xls = pd.read_excel(path_xls, index_col=0)\n",
    "    data_xls.to_csv(path_csv, encoding='utf-8')\n",
    "    return path_csv\n",
    "\n",
    "def cdf(path, x, data, xl, xr, colors, linestyle, ylabel,rotation=0,\n",
    "        xlabel=None, figsize=figsize, labels=None,\n",
    "        **kwargs):\n",
    "    if labels is not None:\n",
    "        if len(labels) != len(data): raise ValueError('label num error')\n",
    "    if colors is not None:\n",
    "        if len(colors) != len(data): raise ValueError('colors num error')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if 'x_step' in kwargs:\n",
    "        ax.set_xticks(np.arange(xl, xr + 1, kwargs['x_step']))\n",
    "\n",
    "    out_format = '{x:,.0f}'\n",
    "    if isinstance(xl, np.float64):\n",
    "        out_format = '{x:,.1f}'\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        la = labels[i]\n",
    "        color = colors[i]\n",
    "        ls = linestyle[i]\n",
    "        plt.plot(x, data[i], color=color, label=la, linewidth=linewidth, linestyle=ls)\n",
    "        plt.gca().xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(out_format))\n",
    "    \n",
    "    plt.locator_params(axis='x', nbins=10)\n",
    "    plt.xlim(xl, xr)\n",
    "    plt.xticks(size=tick_fontsize,rotation=rotation)\n",
    "    plt.xlabel(xlabel, size=label_fontsize)\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.yticks(size=tick_fontsize)\n",
    "    plt.ylabel(ylabel, size=label_fontsize)\n",
    "\n",
    "    if len(labels) > 1:\n",
    "        plt.legend(fontsize=legend_fontsize, loc=4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if 'hline' in kwargs:\n",
    "        hline = kwargs['hline']\n",
    "        for i in range(len(data)):\n",
    "            first_line = LineString(np.column_stack((x, data[i])))\n",
    "            second_line = LineString(np.column_stack((x, [hline for i in range(len(x))])))\n",
    "            intersection = first_line.intersection(second_line)\n",
    "\n",
    "            arr_x, arr_y = intersection.xy\n",
    "            for x_i in arr_x:\n",
    "                plt.axvline(x=x_i, ymin=0, ymax=hline, linewidth=indicator_linewidth, color=indicator_color,\n",
    "                            linestyle=indicator_linestyle)\n",
    "            for ind, y_i in enumerate(arr_y):\n",
    "                plt.axhline(y=y_i, xmin=0, xmax=arr_x[ind] / xr, linewidth=indicator_linewidth, color=indicator_color,\n",
    "                            linestyle=indicator_linestyle)\n",
    "\n",
    "    plt.savefig(path, dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "def active_time_similar():\n",
    "    path_xls = \"active_time_similar.xlsx\"\n",
    "    path_csv = xlsx_to_csv_pd(path_xls)\n",
    "    df = pd.read_csv(path_csv, encoding='ISO-8859-15')\n",
    "    all_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        all_data.append(row['time'])\n",
    "\n",
    "    # x = np.linspace(min(all_data), max(all_data))\n",
    "    x = np.linspace(0, 60)\n",
    "    ecdf_all = sm.distributions.ECDF(all_data)\n",
    "    y = ecdf_all(x)\n",
    "\n",
    "    cdf(path=\"active_time_similar.pdf\",\n",
    "               x=x, data=[y], xl=0, xr=60,\n",
    "               xlabel='Active Period(Day)',\n",
    "               hline=0.8,\n",
    "               ylabel='CDF',\n",
    "               labels=['Count'],\n",
    "               colors=['blue'],\n",
    "               linestyle=['-'])\n",
    "\n",
    "\n",
    "def active_time_dep():\n",
    "    path_xls = \"active_time.xlsx\"\n",
    "    path_csv = xlsx_to_csv_pd(path_xls)\n",
    "    df = pd.read_csv(path_csv, encoding='ISO-8859-15')\n",
    "    all_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        all_data.append(row['time'])\n",
    "\n",
    "    # x = np.linspace(min(all_data), max(all_data))\n",
    "    x = np.linspace(0, 140)\n",
    "    ecdf_all = sm.distributions.ECDF(all_data)\n",
    "    y = ecdf_all(x)\n",
    "\n",
    "    cdf(path=\"active_time_dep.pdf\",\n",
    "               x=x, data=[y], xl=0, xr=140,\n",
    "               xlabel='Active Period(Day)',\n",
    "               hline=0.8,\n",
    "               ylabel='CDF',\n",
    "               labels=['Count'],\n",
    "               colors=['blue'],\n",
    "               linestyle=['-'])\n",
    "\n",
    "def active_time_coexist():\n",
    "    path_xls = \"active_time.xlsx\"\n",
    "    path_csv = xlsx_to_csv_pd(path_xls)\n",
    "    df = pd.read_csv(path_csv, encoding='ISO-8859-15')\n",
    "    all_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        all_data.append(row['time'])\n",
    "\n",
    "    # x = np.linspace(min(all_data), max(all_data))\n",
    "    x = np.linspace(0, 100)\n",
    "    ecdf_all = sm.distributions.ECDF(all_data)\n",
    "    y = ecdf_all(x)\n",
    "\n",
    "    cdf(path=\"active_time_dep.pdf\",\n",
    "               x=x, data=[y], xl=0, xr=100,\n",
    "               xlabel='Active Period(Day)',\n",
    "               hline=0.8,\n",
    "               ylabel='CDF',\n",
    "               labels=['Count'],\n",
    "               colors=['blue'],\n",
    "               linestyle=['-'])\n",
    "               \n",
    "\n",
    "## TODO:select different function\n",
    "       \n",
    "active_time_similar()\n",
    "# active_time_dep()\n",
    "# active_time_coexist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
