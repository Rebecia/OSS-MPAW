{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_name = 'published_at'\n",
    "time_name = 'time'\n",
    "def extract_time_difference_from_subgraph(subgraph):\n",
    "    nodes = subgraph['nodes']\n",
    "\n",
    "    for node in nodes:\n",
    "        if node[time_name] != \"Not available\":\n",
    "            node[time_name] = datetime.fromisoformat(node[time_name][:-1])\n",
    "        else:\n",
    "            node[time_name] = None\n",
    "\n",
    "    dates = [node[time_name] for node in nodes if node[time_name] is not None]\n",
    "    if dates:\n",
    "        min_date = min(dates)\n",
    "        max_date = max(dates)\n",
    "        time_diff = max_date - min_date  \n",
    "\n",
    "        time_diff_in_days = time_diff.total_seconds() / 86400  # 86400s = 1d\n",
    "        time_diff_str = f\"{time_diff_in_days:.2f}\"\n",
    "    else:\n",
    "        time_diff_str = 'None'\n",
    "    \n",
    "    return time_diff_str\n",
    "\n",
    "def process_json_files_in_folders(folders):\n",
    "    time_differences = []\n",
    "\n",
    "    for folder_path in folders:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for filename in files:\n",
    "                if filename.endswith('.json'):\n",
    "                    file_path = os.path.join(root, filename)\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        subgraph = json.load(file)\n",
    "                        time_diff_str = extract_time_difference_from_subgraph(subgraph)\n",
    "                        \n",
    "                        time_differences.append({\n",
    "                            'file_path': file_path,\n",
    "                            'time_difference(Day)': time_diff_str\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(time_differences)\n",
    "    output_path = './time_differences_source.xlsx'\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"Time differences saved to {output_path}\")\n",
    "\n",
    "folders = [\n",
    "  'KG/Co-existing_Edge/source_report/npm',\n",
    "  'KG/Co-existing_Edge/source_report/pypi',\n",
    "  'KG/Co-existing_Edge/source_report/ruby'\n",
    "]\n",
    "process_json_files_in_folders(folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_excel(input_excel_path, output_excel_path):\n",
    "    df = pd.read_excel(input_excel_path)\n",
    "\n",
    "    # Create a list to store the max time difference for each cluster\n",
    "    result = []\n",
    "\n",
    "    # Filter out rows where 'published_at' is 'Not available'\n",
    "    df = df[df['published_at'] != 'Not available']\n",
    "\n",
    "    # Ensure the 'published_at' column is in datetime format\n",
    "    df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')\n",
    "\n",
    "    # Iterate through each cluster group\n",
    "    for cluster, group in df.groupby('cluster'):\n",
    "        # Sort the group by published_at\n",
    "        group_sorted = group.sort_values(by='published_at')\n",
    "        \n",
    "        if len(group_sorted) > 1:\n",
    "            time_diff = group_sorted['published_at'].max() - group_sorted['published_at'].min()\n",
    "            # Convert time difference to days, keeping decimals\n",
    "            time_diff_in_days = time_diff.total_seconds() / 86400  # 86400 seconds = 1 day\n",
    "            time_diff_str = f\"{time_diff_in_days:.2f}\"  # Round to 2 decimal places\n",
    "            result.append([\"ruby_\" + str(cluster), time_diff_str])\n",
    "        else:\n",
    "            result.append([\"ruby_\" + str(cluster), \"0.00\"])\n",
    "\n",
    "    result_df = pd.DataFrame(result, columns=['cluster', 'time'])\n",
    "\n",
    "    result_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Results have been saved to {output_excel_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_excel_path = 'KG/Similar_Edge/ruby_end.xlsx'  # Path to input Excel file\n",
    "    output_excel_path = './ruby_active.xlsx'  # Path to output Excel file\n",
    "    process_excel(input_excel_path, output_excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
