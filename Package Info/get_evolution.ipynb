{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP1: sort nodes by time\n",
    "\n",
    "time_name = 'time'\n",
    "# time_name = 'published_at'\n",
    "def sort_nodes(nodes):\n",
    "    available_nodes = []\n",
    "    not_available_nodes = []\n",
    "\n",
    "    for node in nodes:\n",
    "        if node[time_name] != \"Not available\":\n",
    "            available_nodes.append(node)\n",
    "        else:\n",
    "            not_available_nodes.append(node)\n",
    "\n",
    "    available_nodes.sort(key=lambda x: datetime.fromisoformat(x[time_name].replace(\"Z\", \"+00:00\")))\n",
    "    not_available_nodes.sort(key=lambda x: x['name'].lower())\n",
    "    sorted_nodes = available_nodes + not_available_nodes\n",
    "\n",
    "    return sorted_nodes\n",
    "\n",
    "def process_json_files_in_folder(folder_path):\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(folder_path, json_file), 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if 'nodes' in data:\n",
    "            sorted_nodes = sort_nodes(data['nodes'])\n",
    "            data['nodes'] = sorted_nodes\n",
    "\n",
    "        with open(os.path.join(folder_path, json_file), 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Processed and sorted nodes in {json_file}\")\n",
    "\n",
    "def process_multiple_folders(folder_paths):\n",
    "    for folder_path in folder_paths:\n",
    "        if os.path.exists(folder_path):\n",
    "            process_json_files_in_folder(folder_path)\n",
    "        else:\n",
    "            print(f\"Folder {folder_path} does not exist.\")\n",
    "\n",
    "folder_paths = [\n",
    "# # # dependent-hidden graph\n",
    "#   'KG/Dependency_Edge/metadata_dep/npm',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/npm',\n",
    "#   'KG/Dependency_Edge/metadata_dep/pypi',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/pypi',\n",
    "#   'KG/Dependency_Edge/metadata_dep/ruby',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/ruby'\n",
    "\n",
    "# co-existing graph\n",
    "  'KG/Co-existing_Edge/source_report/npm',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/npm',\n",
    "  'KG/Co-existing_Edge/source_report/pypi',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/pypi',\n",
    "  'KG/Co-existing_Edge/source_report/ruby',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/ruby'\n",
    "]\n",
    "\n",
    "process_multiple_folders(folder_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP2: generate evolution for depdent-hidden/co-existing graphs\n",
    "def replace_nan_with_none(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: replace_nan_with_none(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [replace_nan_with_none(item) for item in data]\n",
    "    elif data is None or (isinstance(data, float) and math.isnan(data)):\n",
    "        return None\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "total_name_change = 0\n",
    "total_version_change = 0\n",
    "total_description_change = 0\n",
    "total_dependencies_change = 0\n",
    "total_code_change = 0\n",
    "total_change_num = 0\n",
    "\n",
    "def compare_nodes(prev_node, curr_node):\n",
    "    global total_name_change, total_version_change, total_description_change, total_dependencies_change, total_code_change, total_change_num\n",
    "\n",
    "    prev_node = replace_nan_with_none(prev_node)\n",
    "    curr_node = replace_nan_with_none(curr_node)\n",
    "\n",
    "    if prev_node['name'] != curr_node['name']:\n",
    "        total_name_change += 1\n",
    "    if (prev_node['name'] == curr_node['name']) and (prev_node.get('version', 'none') != curr_node.get('version', 'none')):\n",
    "        total_version_change += 1\n",
    "    if (prev_node.get('SHA-256', 'none') != 'none') and (curr_node.get('SHA-256', 'none') != 'none') and (prev_node['description'] != curr_node['description']):\n",
    "        total_description_change += 1\n",
    "    if (prev_node.get('SHA-256', 'none') != 'none') and (curr_node.get('SHA-256', 'none') != 'none') and (prev_node.get('SHA-256', 'none') != curr_node.get('SHA-256', 'none')):\n",
    "        total_code_change += 1\n",
    "    if (prev_node.get('SHA-256', 'none') != 'none') and (curr_node.get('SHA-256', 'none') != 'none') and (prev_node['dependencies'] != curr_node['dependencies']):\n",
    "        total_dependencies_change += 1\n",
    "\n",
    "def process_json_files_in_folder(folder_path):\n",
    "    global total_name_change, total_version_change, total_description_change, total_dependencies_change, total_code_change\n",
    "    \n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(folder_path, json_file), 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        nodes = data.get('nodes', [])\n",
    "        \n",
    "        for i in range(1, len(nodes)):\n",
    "            prev_node = nodes[i - 1]\n",
    "            curr_node = nodes[i]\n",
    "            compare_nodes(prev_node, curr_node)\n",
    "\n",
    "def process_multiple_folders(folder_paths):\n",
    "    for folder_path in folder_paths:\n",
    "        process_json_files_in_folder(folder_path)\n",
    "    \n",
    "    total_change_num = total_name_change+total_version_change\n",
    "    final_results = {\n",
    "        # \"CN\": total_name_change / (total_name_change + total_version_change + total_description_change + total_dependencies_change + total_code_change),\n",
    "        # \"CV\": total_version_change / (total_name_change + total_version_change + total_description_change + total_dependencies_change + total_code_change),\n",
    "        # \"CD\": total_description_change / (total_name_change + total_version_change + total_description_change + total_dependencies_change + total_code_change),\n",
    "        # \"CDep\": total_dependencies_change / (total_name_change + total_version_change + total_description_change + total_dependencies_change + total_code_change),\n",
    "        # \"CC\": total_code_change / (total_name_change + total_version_change + total_description_change + total_dependencies_change + total_code_change)\n",
    "        \"CN\": total_name_change / total_change_num,\n",
    "        \"CV\": total_version_change / total_change_num,\n",
    "        \"CD\": total_description_change / total_change_num,\n",
    "        \"CDep\": total_dependencies_change / total_change_num,\n",
    "        \"CC\": total_code_change / total_change_num\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(list(final_results.items()), columns=['Change Type', 'Value'])\n",
    "    \n",
    "    output_file = './evolution.xlsx'\n",
    "    df.to_excel(output_file, index=False)\n",
    "    \n",
    "    print(f\"Final aggregated results saved to {output_file}\")\n",
    "    print(\"Final aggregated results across all folders:\", final_results)\n",
    "\n",
    "folder_paths = [\n",
    "# # # dependent-hidden graph\n",
    "#   'KG/Dependency_Edge/metadata_dep/npm',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/npm',\n",
    "#   'KG/Dependency_Edge/metadata_dep/pypi',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/pypi',\n",
    "#   'KG/Dependency_Edge/metadata_dep/ruby',\n",
    "#   'KG/Dependency_Edge/sourcecode_dep/ruby'\n",
    "\n",
    "# co-existing graph\n",
    "  'KG/Co-existing_Edge/source_report/npm',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/npm',\n",
    "  'KG/Co-existing_Edge/source_report/pypi',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/pypi',\n",
    "  'KG/Co-existing_Edge/source_report/ruby',\n",
    "  'KG/Co-existing_Edge/WebCrawler_report/ruby'\n",
    "]\n",
    "\n",
    "process_multiple_folders(folder_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP2: generate evolution for similar  graphs\n",
    "def replace_nan_with_none(node):\n",
    "    return {k: (None if v != v else v) for k, v in node.items()}  \n",
    "\n",
    "def process_multiple_excel(excel_files, output_file):\n",
    "    all_results = []\n",
    "\n",
    "    for excel_file in excel_files:\n",
    "        df = pd.read_excel(excel_file)\n",
    "\n",
    "        required_columns = ['cluster', 'published_at', 'name', 'version', 'SHA-256', 'description', 'dependencies']\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            print(f\"Error: The Excel file {excel_file} must contain 'cluster', 'published_at', 'name', 'version', 'SHA-256', 'description', and 'dependencies' columns.\")\n",
    "            continue\n",
    "        \n",
    "        total_name_change = 0\n",
    "        total_version_change = 0\n",
    "        total_description_change = 0\n",
    "        total_dependencies_change = 0\n",
    "        total_code_change = 0\n",
    "        total_change_num = 0\n",
    "\n",
    "        for cluster, group in df.groupby('cluster'):\n",
    "            group_sorted = group.sort_values(by='published_at')\n",
    "\n",
    "            prev_node = None\n",
    "            for index, curr_node in group_sorted.iterrows():\n",
    "                if prev_node is not None:\n",
    "                    prev_node = replace_nan_with_none(prev_node)\n",
    "                    curr_node = replace_nan_with_none(curr_node)\n",
    "\n",
    "                    if prev_node['name'] != curr_node['name']:\n",
    "                        total_name_change += 1\n",
    "                    if prev_node['name'] == curr_node['name'] and prev_node.get('version', 'none') != curr_node.get('version', 'none'):\n",
    "                        total_version_change += 1\n",
    "                    if prev_node.get('SHA-256', 'none') != 'none' and curr_node.get('SHA-256', 'none') != 'none' and prev_node['description'] != curr_node['description']:\n",
    "                        total_description_change += 1\n",
    "                    if prev_node.get('SHA-256', 'none') != 'none' and curr_node.get('SHA-256', 'none') != 'none' and prev_node.get('SHA-256', 'none') != curr_node.get('SHA-256', 'none'):\n",
    "                        total_code_change += 1\n",
    "                    if prev_node.get('SHA-256', 'none') != 'none' and curr_node.get('SHA-256', 'none') != 'none' and prev_node['dependencies'] != curr_node['dependencies']:\n",
    "                        total_dependencies_change += 1\n",
    "\n",
    "                prev_node = curr_node\n",
    "\n",
    "        total_change_num = total_name_change + total_version_change \n",
    "        all_results.append([excel_file,total_name_change, total_version_change, total_description_change, total_dependencies_change, total_code_change, total_change_num])\n",
    "\n",
    "    result_df = pd.DataFrame(all_results, columns=['File_name','Total Name Change', 'Total Version Change', 'Total Description Change', 'Total Dependencies Change', 'Total Code Change', 'Total Change Num'])\n",
    "\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "    print(f\"Updated Excel file has been saved to {output_file}\")\n",
    "\n",
    "excel_files = [\n",
    "    'KG/Similar_Edge/npm_end.xlsx', \n",
    "    'KG/Similar_Edge/pypi_end.xlsx',  \n",
    "    'KG/Similar_Edge/ruby_end.xlsx',\n",
    "]\n",
    "\n",
    "output_excel_path = './evolution.xlsx'  \n",
    "process_multiple_excel(excel_files, output_excel_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
