{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sourcecode_dep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as plt\n",
    " \n",
    "file_path = ''\n",
    "excel_data = pd.read_excel(file_path)\n",
    "dependency_graph = nx.DiGraph()\n",
    "\n",
    " \n",
    "for _, row in excel_data.iterrows():\n",
    "    source = row['name_version']\n",
    "    target = row['Name_Version_file']\n",
    "    \n",
    "     \n",
    "    dependency_graph.add_node(source, \n",
    "                              yuan=row['Source']\n",
    "                             )\n",
    "    dependency_graph.add_node(target, \n",
    "                              yuan1=row['Source_file'],\n",
    "                              File=row['File'],\n",
    "                              Code=row['Code'])\n",
    "\n",
    "     \n",
    "    dependency_graph.add_edge(target, source)\n",
    "\n",
    " \n",
    "graph_data = nx.node_link_data(dependency_graph)\n",
    "\n",
    " \n",
    "with open('./dependency_graph.json', 'w') as f:\n",
    "    json.dump(graph_data, f, indent=4)\n",
    "\n",
    "print('Graph has been saved to dependency_graph.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weakly_connected_components = list(nx.weakly_connected_components(dependency_graph))\n",
    "output_dir = ''\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    " \n",
    "for i, component in enumerate(weakly_connected_components):\n",
    "    if len(component) > 2:   \n",
    "        subgraph = dependency_graph.subgraph(component).copy()\n",
    "\n",
    "         \n",
    "        subgraph_data = nx.node_link_data(subgraph)\n",
    "        with open(os.path.join(output_dir, f'weakly_connected_subgraph_{i}.json'), 'w') as f:\n",
    "            json.dump(subgraph_data, f, indent=4)\n",
    "\n",
    "         \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        pos = nx.spring_layout(subgraph)\n",
    "        nx.draw(subgraph, pos, with_labels=True, node_color='lightgreen', font_weight='bold')\n",
    "        plt.title(f'Weakly Connected Subgraph {i}')\n",
    "        plt.savefig(os.path.join(output_dir, f'weakly_connected_subgraph_{i}.png'))\n",
    "         \n",
    "        plt.close()\n",
    "\n",
    "print(f'Generated {len(weakly_connected_components)} weakly connected subgraphs and saved to {output_dir}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metadata_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "\n",
    "def handle_non_serializable(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    elif isinstance(obj, nx.classes.reportviews.NodeDataView):\n",
    "        return list(obj)\n",
    "     \n",
    "\n",
    "def append_kg_to_json(graph, filename):\n",
    "    json_data = nx.node_link_data(graph)\n",
    "    json_str = json.dumps(json_data, indent=4, default=handle_non_serializable)\n",
    "    with open(filename, 'a', encoding='utf-8') as json_file:\n",
    "        json_file.write(json_str)\n",
    "        json_file.write(\"\\n\")   \n",
    "\n",
    "def bulid_kg():\n",
    "     \n",
    "     \n",
    "    excel_path = ''   \n",
    "    sheet_name = ''         \n",
    "     \n",
    "    df = pd.read_excel(excel_path,sheet_name=sheet_name)\n",
    "    graph = nx.Graph()\n",
    "    node_count = 0\n",
    "\n",
    "     \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Knowledge Graph\"):\n",
    "         \n",
    "        node_data = {\n",
    "            \"package_id\": row['ID'],\n",
    "            \"OSS\": row['OSS'],\n",
    "            \"Source\": row['Source'],\n",
    "            \"Status\": row['Status'],\n",
    "            \"filepath\": row['Filepath'],\n",
    "            \"package_name\": row['name_version'],\n",
    "            \"name\":row['name'],\n",
    "            \"verison\":row['version'],\n",
    "            \"published_at\":row['published_at'],\n",
    "            \"description\":row['description'],\n",
    "            \"author\":row['author'],\n",
    "            \"maintainers\":row['maintainers'],\n",
    "            \"repository_url\":row['repository_url'],\n",
    "            \"dependencies\":row['dependencies'],\n",
    "\n",
    "\n",
    "            \"edge_dependency\": list()\n",
    "\n",
    "        }\n",
    "\n",
    "         \n",
    "        for key, value in node_data.items():\n",
    "            if pd.isna(value):\n",
    "                node_data[key] = None\n",
    "         \n",
    "        graph.add_node(row['ID'], **node_data)\n",
    "        node_count += 1\n",
    "        \n",
    "        dependency_list = node_data['dependencies'].split(', ') if node_data['dependencies'] else []\n",
    "\n",
    "         \n",
    "        for other_index, other_row in df.iterrows():\n",
    "            if index != other_index:\n",
    "                other_id = other_row['ID']\n",
    "                other_name = other_row['name']\n",
    "\n",
    "                 \n",
    "                current_name = row['name']\n",
    "\n",
    "                 \n",
    "                if pd.notna(other_name) and other_name != current_name and any(dep.strip() == other_name for dep in dependency_list):\n",
    "                    graph.add_edge(row['ID'], other_id)\n",
    "                    graph.nodes[row['ID']].setdefault('edge_dependency', []).append(other_id)\n",
    "\n",
    "\n",
    "     \n",
    "    json_data = nx.node_link_data(graph)\n",
    "    json_str = json.dumps(json_data, indent=4, default=handle_non_serializable)\n",
    "    with open('', 'w', encoding='utf-8') as json_file:\n",
    "        json_file.write(json_str)\n",
    "        new_source_publish = None if pd.isna(new_source_publish) or new_source_publish == '' else new_source_publish\n",
    "\n",
    "bulid_kg()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm   \n",
    "\n",
    " \n",
    "with open('', 'r') as json_file:\n",
    "    graph_data = json.load(json_file)\n",
    "    knowledge_graph = nx.node_link_graph(graph_data)\n",
    "\n",
    " \n",
    "connected_components = list(nx.connected_components(knowledge_graph))\n",
    "\n",
    " \n",
    "for i, component in tqdm(enumerate(connected_components, 1), total=len(connected_components), desc=\"Processing Subgraphs\"):\n",
    "     \n",
    "    if len(component) > 1:\n",
    "        subgraph = knowledge_graph.subgraph(component)\n",
    "        \n",
    "         \n",
    "        subgraph_data = nx.node_link_data(subgraph)\n",
    "        subgraph_json_str = json.dumps(subgraph_data, indent=4)\n",
    "\n",
    "        with open(f'subgraph_{i}.json', 'w') as subgraph_json_file:\n",
    "            subgraph_json_file.write(subgraph_json_str)\n",
    "\n",
    "         \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        pos = nx.spring_layout(subgraph)   \n",
    "        nx.draw(subgraph, pos, with_labels=True, node_color='skyblue', node_size=500, font_size=8)\n",
    "        plt.title(f\"SubGraph {i}\")\n",
    "         \n",
    "        plt.savefig(f'subgraph_{i}.pdf', format='pdf', bbox_inches='tight')\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of subgraph deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_json_files(folder_path):\n",
    "    json_files = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                json_data = json.load(file)\n",
    "                json_files[file_name] = json_data\n",
    "    return json_files\n",
    "\n",
    "def compare_nodes(nodes1, nodes2):\n",
    "    names1 = {node['package_name'] for node in nodes1}\n",
    "    names2 = {node['id'] for node in nodes2}\n",
    "    return names1.issubset(names2)\n",
    "\n",
    "def find_matching_jsons(folder1_jsons, folder2_jsons):\n",
    "    matching_json_pairs = []\n",
    "    \n",
    "    for file1_name, data1 in folder1_jsons.items():\n",
    "        nodes1 = data1.get('nodes', [])\n",
    "        \n",
    "        for file2_name, data2 in folder2_jsons.items():\n",
    "            nodes2 = data2.get('nodes', [])\n",
    "            \n",
    "            if compare_nodes(nodes1, nodes2):\n",
    "                matching_json_pairs.append((file1_name, file2_name))\n",
    "    \n",
    "    return matching_json_pairs\n",
    "\n",
    "def main(folder1, folder2):\n",
    "    folder1_jsons = load_json_files(folder1)\n",
    "    folder2_jsons = load_json_files(folder2)\n",
    "    \n",
    "    matching_json_pairs = find_matching_jsons(folder1_jsons, folder2_jsons)\n",
    "    \n",
    "    if matching_json_pairs:\n",
    "        for file1_name, file2_name in matching_json_pairs:\n",
    "            print(f\"File '{file1_name}' from Folder 1 matches with File '{file2_name}' from Folder 2.\")\n",
    "    else:\n",
    "        print(\"No matching JSON files found.\")\n",
    "    return matching_json_pairs\n",
    "\n",
    " \n",
    "folder1_path = ''\n",
    "folder2_path = ''   \n",
    "\n",
    "matching_json_pairs = main(folder1_path, folder2_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
